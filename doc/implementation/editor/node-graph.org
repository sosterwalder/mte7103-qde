The functionality of the node graph is, as its name states, to represent a data
structure composed of nodes and edges. Each scene from the scene graph is
represented within the node graph as such a data structure.

The nodes are the building blocks of a real time animation. They represent
different aspects, such as scenes themselves, time line clips, models, cameras,
lights, materials, generic operators and effects. These aspects are only examples
(coming from \cite[p. 30 and 31]{osterwalder_qde_2016}) as the node structure
must be expandable for allowing the addition of new nodes.

The implementation of the scene graph component was relatively straightforward
partly due to its structure and partly due to the used data model and
representation. The node graph component however, seems to be a bit more complex.

To get a first overview and to manage its complexity, it might be good to
identify its sub components first before implementing them.
When thinking about the implementation of the node graph, one may identify the
following sub components:

- Nodes
  - Domain model :: Holds data of a node, like its definition, its inputs and so
                    on.
  - Definitions  :: Represents a domain model as JSON data structure.
  - Controller   :: Handles the loading of node definitions as well as the
                    creation of node instances.
  - View model   :: Represents a node within the graphical user interface.
- Scenes
  - Domain model :: Holds the data of a scene, e.g. its nodes.
  - Controller   :: Handles scene related actions, like when a node is added to
                    a scene, when the scene was changed or when a node within a
                    scene was selected.
  - View model   :: Defines the graphical representation of scene which can be
                    represented by the corresponding view. Basically the scene
                    view model is a canvas consisting of nodes.
  - View         :: Represents scenes in terms of scene view models within the
                    graphical user interface.

One of the most basic sub components are the definitions of nodes. But what are
those definitions actually? What do they actually define? There is not only one
answer to this question, it is simply a matter of how the implementation is
being done and therefore a set of decisions.

The whole (rendering) system shall not be bound to only one representation of
nodes, e.g. triangle based meshes. Instead it shall let the user decide, what
representation is the most fitting for the goal he wants to achieve.

At this point the system shall be able to theoretically support multiple kinds of
node representations: Images, triangle based meshes and solid modeling through
function modeling (using signed distance functions for modeling implicit
surfaces). Whereas triangle based meshes may either be loaded from externally
defined files (e.g. in the Filmbox (FBX), the Alembic (ABC) or the Object file
format (OBJ)) or directly be generated using procedural mesh generation.

# Implementing all of the mentioned methodologies for representing nodes is not
# realistic within the time frame of this project, therefore only images and solid
# modeling will be implemented.

When implementing the nodes, keep in mind that the nodes are part of a graph,
hence the name node graph, and are therefore typically connected by edges. This
means that the graph gets evaluated recursively by its nodes. However, the goal
is to have OpenGL shading language (GLSL) code at the end, independent of the
node types.

From this point of view it is theoretically possible to let the user define shader
code directly within a node (definition) and to simply evaluate this code, which
adds a lot of (creative) freedom. The problem with this approach is though, that
image and triangle based mesh nodes are not fully implementable by using shader
code only. Instead they have specific requirements, which are only perform-able
on the CPU instead of the GPU (e.g. allocating buffer objects).

When thinking of nodes used for solid modeling however, it may appear, that they
may be evaluated directly, without the need for pre-processing, as they are
fully implementable using shader code only. This is kind of misleading however
as each node has its own definition which has to be added to shader and this
definition is then used in a mapping function to compose the scene. This would
mean to add a definition of a node over and over again, when spawning multiple
instances of the same node type, which results in overhead bloating the shader.
It is therefore necessary to pre-process solid modeling nodes too, exactly as
triangle mesh based and image nodes, for being able to use multiple instances of
the same node type within a scene while having the definition added only once.

All of these thoughts sum up in one central question for the implementation:
Shall objects be predefined within the code (and therefore only nodes accepted
whose type and sub type match those of predefined nodes) or shall all objects be
defined externally using files?

This is a question which is not so easy to answer. Both methods have their
advantages and disadvantages. Pre-defining nodes within the code minimizes
unexpected behavior of the application. Only known and well-defined nodes are
processed.

But what if someone would like to have a new node type which is not yet defined?
The node type has to be implemented first. As Python is used for the editor
application, this is not really a problem as the code is interpreted each time
and is therefore not being compiled. Nevertheless such changes follow a certain
process, such as making the actual changes, reviewing and checking-in the code
and so on, which the user normally does not want to be bothered with.
Furthermore, when thinking about the player application, the problem of the
necessity to recompile the code is definitively given. The player will be
implemented in C, as there is the need for performance, which Python may not
fulfill satisfactorily.

Considering these aspects, the external definition of nodes is chosen. This may
result in nodes which cannot be evaluated or which have unwanted effects. As it
is (most likely) in the users best interest to create (for his taste) appealing
real time animations, it can be assumed, that the user will try avoiding to
create such nodes or quickly correct faulty nodes or simply does not use such nodes.

- Pre-process
- Process
- Post-process

To ensure a enjoyable user experience, it is important to provide the user with
predefined nodes to choose from --- independent from their type.

To recapitulate, the following node types and definitions are envisaged:

- Nodes, that can be evaluated directly
  - Solid modeling objects
    - Sphere
    - Cube
    - Plane
    - ...
  - Solid modeling operations
    - Transformation
    - Scaling
    - Rotation
    - Union
    - Differentiation
    - ...
  - Post-processing effects
    - Blur
    - Glare
    - ...
- Nodes, that cannot be evaluated directly
  - Procedural generated mesh nodes
    - Sphere
    - Cube
    - Plane
    - ...
  - Externally defined meshes
    - Filmbox (FBX)
    - Alembic (ABC)
    - Object file format (OBJ)
  - Images

As stated before, it would illusive wanting to implement all of these nodes, as
the time frame of this project is simply too narrow and therefore only nodes,
that can be evaluated directly, as well as images are considered for
implementation.

As not to complicate things, the implementation is kept as simple as
possible: If a node has a =code= block in its definition, the application
assumes that is possible to evaluate this node directly. If a node has no such
block, its type and its sub-type must be implemented within the application,
otherwise the node will simply be not evaluated.

To get the node graph implementation started, a sample node definition is
implemented as well as its defining class.

**** Node definitions

Node definitions are implemented in the
JSON[fn:9d5e4e40b523c9e:http://www.ecma-international.org/publications/files/ECMA-ST/Ecma-262.pdf]
format and are placed in the =data/nodes/= sub-directory, seen from the main
directory. A node definition contains at least a type and a sub type. Optional
it may contain a source block, which can be evaluated directly.
